{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Builder Tutorial number 10\n",
    "\n",
    "The builder tutorials demonstrate how to build an operational GSFLOW model using `pyGSFLOW` from shapefile, DEM, and other common data sources. These tutorials focus on the `gsflow.builder` classes.\n",
    "\n",
    "## Working with climate information\n",
    "\n",
    "In this tutorial, we give an overview of how to translate climate information to PRMS parameters. The methods outlined here use raster resampling methods outlined in `Builder_tutorial_2` and use pandas dataframes to create climate information. Two different climate representation methods are presented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shapefile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import flopy\n",
    "from gsflow.builder import builder_utils as bu\n",
    "import gsflow\n",
    "\n",
    "# silence pandas setting with copy warning\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying temp_1sta module parameters to the Sagehen 50m example problem\n",
    "\n",
    "The temp_1sta module in PRMS allows the user to define their climate using a single climate station and adjustment factors based on lapse rates and aspect. In this example the methods are applied directly to the Sagehen 50m model as they are presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by defining paths and loading the PRMS parameter file from the previous tutorial and the MODFLOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the input and output data paths\n",
    "input_ws = os.path.join(\"data\", \"sagehen\", \"50m_tutorials\")\n",
    "geospatial_ws = os.path.join(\"data\", \"geospatial\")\n",
    "output_ws = os.path.join(\"data\", \"temp\")\n",
    "\n",
    "# Set modflow model and the prms parameter file paths\n",
    "modflow_nam = \"sagehen_50m.nam\"\n",
    "parameter_file = os.path.join(input_ws, \"sagehen_50m_lu_soil.params\")\n",
    "\n",
    "# set the pour point shapefile path\n",
    "shp_file = os.path.join(geospatial_ws, \"model_points.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MODFLOW model and PRMS parameter file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = gsflow.modflow.Modflow.load(modflow_nam, model_ws=input_ws)\n",
    "parameters = gsflow.prms.PrmsParameters.load_from_file(parameter_file)\n",
    "\n",
    "# check the modelgrid coordinate information to make sure it loaded properly\n",
    "print(ml.modelgrid.xoffset, ml.modelgrid.yoffset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths to climate information\n",
    "\n",
    "In this example we use both climate station information from Sagehen Creek co-operative station (University of California, Berkely, 2008) and PRISM 30-year normals (PRISM Climate Group, 2022) rasters to define the climate.\n",
    "\n",
    "Let's start by defining paths for the climate station information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_ws = os.path.join(geospatial_ws, \"climate\")\n",
    "\n",
    "climate_sta_file = os.path.join(climate_ws, \"sagehen_climate.csv\")\n",
    "lapse_rate_file = os.path.join(climate_ws, \"sagehen_lapse_rates.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's programatically define the paths for the monthly PRISM 30 year normals raster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism = {\"ppt_utm\": [], \"tmax_utm\": [], \"tmin_utm\": []}\n",
    "for folder in prism.keys():\n",
    "    for f in os.listdir(os.path.join(climate_ws, folder)):\n",
    "        if os.path.isfile(os.path.join(climate_ws, folder, f)) and f.endswith(\".img\"):\n",
    "            prism[folder].append(os.path.join(climate_ws, folder, f))\n",
    "\n",
    "# inspect ppt to make sure we've collected all of the precip filenames\n",
    "for f in prism[\"ppt_utm\"]:\n",
    "    print(os.path.split(f)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the climate station information\n",
    "\n",
    "The climate station information is stored in a csv file. This allows it to be easily loaded in python using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_df = pd.read_csv(climate_sta_file)\n",
    "lapse_df = pd.read_csv(lapse_rate_file)\n",
    "\n",
    "climate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runoff information from the USGS gage 10343500 SAGEHEN C NR TRUCKEE CA is also stored in the climate station information file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the climate Raster Data\n",
    "\n",
    "Loading and resampling of raster data is performed using the Raster resampling methods outlined in Builder tutorial 2. Because this is a computationally intensive process, code is provided for completeness, however the default behavior of this notebook is to skip this step and load the saved ASCII versions. Change `resample_rasters=False` to `resample_rasters=True` to run the raster sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_rasters = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all the datatypes and rasters to create a single yearly resampled file with monthly values entries\n",
    "if resample_rasters:\n",
    "    rs_files = {\n",
    "        \"ppt_utm\": os.path.join(output_ws, \"ppt_50m.txt\"),\n",
    "        \"tmax_utm\": os.path.join(output_ws, \"tmax_50m.txt\"),\n",
    "        \"tmin_utm\": os.path.join(output_ws, \"tmin_50m.txt\")\n",
    "    }\n",
    "    \n",
    "    # create a loop to reduce code clutter\n",
    "    for ctype, raster_list in prism.items():\n",
    "        output = []\n",
    "        rs_file = rs_files[ctype]\n",
    "        for raster_file in raster_list:\n",
    "            raster = flopy.utils.Raster.load(raster_file)\n",
    "            array = raster.resample_to_grid(\n",
    "                ml.modelgrid,\n",
    "                band=raster.bands[0],\n",
    "                method=\"linear\",\n",
    "            )\n",
    "            output.append(array.ravel())\n",
    "        output = np.array(output)\n",
    "        print(os.path.split(rs_file)[-1])\n",
    "        np.savetxt(rs_file, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the resampled raster data\n",
    "\n",
    "Resampled raster data are saved as delimited ascii files and can be easily loaded into numpy arrays.\n",
    "\n",
    "Define the paths to the resampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt_file = os.path.join(input_ws, \"ppt_50m.txt\")\n",
    "tmax_file = os.path.join(input_ws, \"tmax_50m.txt\")\n",
    "tmin_file = os.path.join(input_ws, \"tmin_50m.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data into numpy arrays and reshape to appropriate shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhru = ml.modelgrid.nnodes\n",
    "print(nhru)\n",
    "ppt = np.genfromtxt(ppt_file).reshape(12, nhru)\n",
    "tmax = np.genfromtxt(tmax_file).reshape(12, nhru)\n",
    "tmin = np.genfromtxt(tmin_file).reshape(12, nhru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the PRMS Data File for temp_1sta\n",
    "\n",
    "pyGSFLOW includes the `PrmsData` class to allow reading, writing, and editing of climate station data files. This section will show how to go from a pandas dataframe to a dataframe commpatible with `PrmsData`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1st)** add date columns to the dataframe using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_df = bu.add_prms_date_columns_to_df(climate_df, \"date\")\n",
    "\n",
    "climate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2nd)** rename the observation columns to have the zero based station number in their name. This is important because PRMS can use multiple climate stations with other climate modeules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_df.rename(\n",
    "    columns={\n",
    "        'precip': 'precip_0',\n",
    "        'tmin': 'tmin_0',\n",
    "        'tmax': 'tmax_0',\n",
    "        'runoff': 'runoff_0',\n",
    "        'date': 'Date'\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3rd)** reorder the datafame so Year, Month, Day, Hour, Minute, and Second are the first entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdfcols = [\n",
    "        \"Year\", \"Month\", \"Day\", \"Hour\", \"Minute\", \"Second\",\n",
    "        \"tmax_0\", \"tmin_0\", \"precip_0\", \"runoff_0\", \"Date\"\n",
    "    ]\n",
    "climate_df = climate_df[cdfcols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4th)** perform any necessary unit conversions before building the `PrmsData` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_df[\"tmax_0\"] = bu.fahrenheit_to_celsius(climate_df[\"tmax_0\"].values)\n",
    "climate_df[\"tmin_0\"] = bu.fahrenheit_to_celsius(climate_df[\"tmin_0\"].values)\n",
    "climate_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally build the `PrmsData` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prms_data = gsflow.prms.PrmsData(data_df=climate_df)\n",
    "prms_data.data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building climate `ParameterRecord` objects\n",
    "\n",
    "The `builder_utils` module contains a number of functions that can be used to build `ParameterRecord` objects that can then be added to an existing `PrmsParameter` object (and later written to file).\n",
    "\n",
    "Here we show the included climate methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean montly values from each ppt, tmax, and tmin for use in calculations\n",
    "mean_ppt = bu.get_mean_monthly_from_df(climate_df, \"precip_0\")\n",
    "mean_tmax = bu.get_mean_monthly_from_df(climate_df, \"tmax_0\", temperature=True)\n",
    "mean_tmin = bu.get_mean_monthly_from_df(climate_df, \"precip_0\", temperature=True)\n",
    "\n",
    "# calculate rain adj and snow adj factors from PRISM and means\n",
    "rain_adj = bu.rain_adj(ppt, mean_ppt)\n",
    "snow_adj = bu.snow_adj(ppt, mean_ppt)\n",
    "\n",
    "# set lapse rates (convert to celsius in line)\n",
    "tmin_lapse = bu.tmin_lapse(lapse_df.tmin_lapse.values * (5 / 9))\n",
    "tmax_lapse = bu.tmax_lapse(lapse_df.tmax_lapse.values * (5 / 9))\n",
    "\n",
    "# tmax and tmin adj are set to zero b/c lapse rates are used in sagehen\n",
    "tmax_adj = bu.tmax_adj(nhru)\n",
    "tmin_adj = bu.tmin_adj(nhru)\n",
    "\n",
    "# calculate the jensen haise coeficients\n",
    "jh_coef = bu.calculate_jensen_haise(ml.modelgrid.top, mean_tmin, mean_tmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding climate `ParameterRecord` objects to the `PrmsParameters` object\n",
    "\n",
    "In this section `ParameterRecord` objects are added to the `PrmsParameters` object using the built in `add_record_object` method.\n",
    "\n",
    "The `add_record_object` method has two parameters:\n",
    "   - `record_object` : a `ParameterRecord` object\n",
    "   - `replace` : bool, a flag to replace an existing parameter if it exists. Default is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters.add_record_object(rain_adj)\n",
    "parameters.add_record_object(snow_adj)\n",
    "parameters.add_record_object(tmin_lapse)\n",
    "parameters.add_record_object(tmax_lapse)\n",
    "parameters.add_record_object(tmax_adj)\n",
    "parameters.add_record_object(tmin_adj)\n",
    "parameters.add_record_object(jh_coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the temperature station elevation to the `PrmsParameters` object\n",
    "\n",
    "The `ParameterRecord` allows users to create a new record and add it to the object using the `add_record()` method. This method has a number of input parameters and the most important ones are described here:\n",
    "   - `name` : name of the parameter\n",
    "   - `values` : list of parameter values\n",
    "   - `dimensions` : 2 dimensional list of parameter dimensions in the format [[dimension name, dimesnion value], ...] ex. [[\"nmonths\", 12], [\"nhru\", 6391]]\n",
    "   - `datatype` : prms data type, 1=int, 2=float, 3=double, 4=string\n",
    "   - `replace` : bool, if true replace existing `ParameterRecord`, default is False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters.add_record(\n",
    "    \"tsta_elev\",\n",
    "    values=[1932.4,],\n",
    "    dimensions=[[\"ntemp\", 1]],\n",
    "    datatype=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the PRMS outlet station and runoff observation location\n",
    "\n",
    "Adding the PRMS outlet station and runoff observation location can be accomplished using the `add_record` method described above. \n",
    "\n",
    "In this example the outlet station and runoff observation location are in the same location as the pour point used for watershed delineation. We'll load up the shapefile and then programatically get the hru number of these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with shapefile.Reader(shp_file) as r:\n",
    "    pour_point = r.shape(0).points\n",
    "\n",
    "# get the zero based node number of the outlet station\n",
    "outlet_sta = ml.modelgrid.intersect(*pour_point[0])\n",
    "outlet_sta = ml.modelgrid.get_node([(0,) + outlet_sta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add the outlet_sta and id_obsrunoff parameters to the `PrmsParameters` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters.add_record(name=\"nobs\", values=[1,])\n",
    "\n",
    "parameters.add_record(\n",
    "    \"outlet_sta\",\n",
    "    values=[outlet_sta[0] + 1,],\n",
    "    dimensions=[[\"one\", 1]],\n",
    "    datatype=1\n",
    ")\n",
    "\n",
    "parameters.add_record(\n",
    "    \"id_obsrunoff\",\n",
    "    values=[outlet_sta[0] + 1, ],\n",
    "    dimensions=[[\"one\", 1]],\n",
    "    datatype=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Sagehen 50m parameter and data files for use in the next notebook\n",
    "\n",
    "The `PrmsParameters` and `PrmsData` objects can be saved using the built in `write()` method. This parameter file will be used in the next notebook, where we assemble, run, and calibrate the GSFLOW model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters.write(os.path.join(output_ws, \"sagehen_50m_ncal.param\"))\n",
    "prms_data.write(os.path.join(output_ws, \"sagehen_50m.data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining climate by HRU with pyGSFLOW\n",
    "\n",
    "An alternative method for defining climate information is to use the `climate_hru` module in GSFLOW or PRMS. When `climate_hru` is specified daily prms climate input values are stored in a `.day` file and their path is specified in the control file.\n",
    "\n",
    "Here is a short example on how to define the climate using climate_hru with pygsflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to GSFLOW control file\n",
    "control_file = os.path.join(input_ws, \"sagehen_50m_initial.control\")\n",
    "\n",
    "# load the control file\n",
    "control = gsflow.ControlFile.load_from_file(control_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the climate module specified in the control file\n",
    "\n",
    "In this example we update the `precip_module` and `temp_module`. Other climate related modules can be updated in the same fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change precip and temp modules to climate_hru\n",
    "control.precip_module = [\"climate_hru\",]\n",
    "control.temp_module = [\"climate_hru\",]\n",
    "\n",
    "print(control.temp_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating climate by hru files\n",
    "\n",
    "The `PrmsDay` class allows users to craft climate by hru files and load, edit, and write climate by hru files. Here is a quick example using the previously loaded Prism precipitation data.\n",
    "\n",
    "In this example, we are assuming that our model is only 12 days long and the prism data is not monthly normals, but daily data for those 12 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# get the date header \n",
    "date_header = gsflow.prms.PrmsDay.date_header\n",
    "cbh_dict = {\"date\": []}\n",
    "\n",
    "# set to the day before our model begins\n",
    "dt = datetime.datetime(2000, 9, 30)\n",
    "# now set the dates\n",
    "for _ in range(1, 13):\n",
    "    dt += datetime.timedelta(days=1)\n",
    "    cbh_dict[\"date\"].append(dt)\n",
    "\n",
    "for hru in range(nhru):\n",
    "    cbh_dict[hru] = ppt[:, hru]\n",
    "    \n",
    "cbh_df = pd.DataFrame(cbh_dict)\n",
    "cbh_df.set_index(\"date\", inplace=True)\n",
    "\n",
    "print(cbh_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding climate by hru data to the `PrmsDay` object\n",
    "\n",
    "The `PrmsDay` object has 4 input parameters that must be supplied to create a new object:\n",
    "   - `f` : file name for the cbh file\n",
    "   - `variable_name` : prms cbh variable name\n",
    "   - `dataframe` : pandas dataframe (formatted as shown in block 31)\n",
    "   - `nhru` : number of hru's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt_day = gsflow.prms.PrmsDay(\n",
    "    os.path.join(output_ws, \"ppt_day.cbh\"),\n",
    "    variable_name=\"hru_ppt\",\n",
    "    dataframe=cbh_df,\n",
    "    nhru=nhru\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the `PrmsDay` object to file\n",
    "\n",
    "The `PrmsDay` object can be written to file using the `write()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt_day.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the climate by hru file name to the `ControlFile` object\n",
    "\n",
    "For this example the `add_record` method can be used to add the `precip_day` parameter to the control file. The `add_record` method takes the following parameters:\n",
    "   - `name` : name of the parameter record\n",
    "   - `values` : list of parameter record values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "control.add_record(\"precip_day\", [\"ppt_day.cbh\",])\n",
    "print(control.precip_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the `ControlFile` object to file\n",
    "\n",
    "The control file can be written from the `ControlFile` object using the `write()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the model workspace for this control file\n",
    "control.model_dir = output_ws\n",
    "\n",
    "# write\n",
    "control.write(\"sagehen_cbh_ex.control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
